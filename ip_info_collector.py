import os
import configparser
import requests
import pandas as pd
from tqdm import tqdm
import time
import concurrent.futures
import logging
import socket
import subprocess
import platform
import threading

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('ip_info_collector.log', encoding='utf-8')
    ]
)
logger = logging.getLogger(__name__)

# è¯»å–é…ç½®æ–‡ä»¶
config = configparser.ConfigParser()
try:
    # æ˜¾å¼æŒ‡å®šUTF-8ç¼–ç 
    with open('config.ini', 'r', encoding='utf-8') as f:
        config.read_file(f)
except FileNotFoundError:
    logger.error("é…ç½®æ–‡ä»¶ config.ini ä¸å­˜åœ¨")
    exit(1)
except Exception as e:
    logger.error(f"è¯»å–é…ç½®æ–‡ä»¶æ—¶å‡ºé”™: {e}")
    exit(1)

def get_config_value(section, option, default=None):
    """å®‰å…¨è·å–é…ç½®å€¼"""
    try:
        return config.get(section, option)
    except (configparser.NoSectionError, configparser.NoOptionError):
        return default

# ä»é…ç½®è·å–å¸¸é‡
INPUT_DIR = get_config_value('directories', 'input_dir', './ips/{port}/')
OUTPUT_DIR = get_config_value('directories', 'output_dir', './ip-info/{port}/')
BATCH_SIZE = int(get_config_value('api', 'batch_size', 100))
MAX_RETRIES = int(get_config_value('api', 'max_retries', 3))
MAX_WORKERS = int(get_config_value('api', 'max_workers', 5))
COUNTRIES = [c.strip() for c in get_config_value('processing', 'countries', 'HK,JP,KR,SG,US').split(',')]
MAX_RECORDS = int(get_config_value('processing', 'max_records_per_country', 10))

# IPæ£€æµ‹ç›¸å…³é…ç½®
ENABLE_IP_CHECK = get_config_value('ip_check', 'enable_ip_check', 'true').lower() == 'true'
CHECK_TIMEOUT = float(get_config_value('ip_check', 'check_timeout', 2))
CHECK_METHOD = get_config_value('ip_check', 'check_method', 'port')
CHECK_PORT = int(get_config_value('ip_check', 'check_port', 443))
CHECK_THREADS = int(get_config_value('ip_check', 'check_threads', 50))

def get_ip_from_file(filename):
    """ä»æ–‡æœ¬æ–‡ä»¶è¯»å–IPåœ°å€"""
    try:
        with open(filename, "r", encoding="utf-8") as f:
            ips = [line.strip() for line in f if line.strip()]
        logger.info(f"ä» {filename} è¯»å–äº† {len(ips)} ä¸ªIP")
        return ips
    except Exception as e:
        logger.error(f"è¯»å–æ–‡ä»¶ {filename} æ—¶å‡ºé”™: {e}")
        return []

def ipinfoapi_batch(ips: list, session, retries=MAX_RETRIES):
    """æ‰¹é‡æŸ¥è¯¢IPä¿¡æ¯ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰"""
    if not ips:
        return []
        
    url = 'http://ip-api.com/batch'
    ips_dict = [{'query': ip, "fields": "city,country,countryCode,isp,org,as,query"} for ip in ips]
    
    for attempt in range(retries):
        try:
            response = session.post(url, json=ips_dict)
            if response.status_code == 200:
                return response.json()
            elif response.status_code == 429:  # é€Ÿç‡é™åˆ¶
                wait_time = 10 * (attempt + 1)  # æŒ‡æ•°é€€é¿
                logger.warning(f"APIé€Ÿç‡å—é™ï¼Œç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                time.sleep(wait_time)
            else:
                logger.error(f'è·å–IPä¿¡æ¯å¤±è´¥: {response.status_code}, {response.reason}')
                return []
        except Exception as e:
            logger.error(f'è¯·æ±‚é”™è¯¯: {e}')
            time.sleep(2)
    
    logger.error(f"ç»è¿‡ {retries} æ¬¡é‡è¯•åä»å¤±è´¥")
    return []

def get_ip_info(ips):
    """è·å–IPä¿¡æ¯ï¼ˆå¹¶è¡Œå¤„ç†ï¼‰"""
    if not ips:
        logger.warning("IPåˆ—è¡¨ä¸ºç©ºï¼Œè·³è¿‡ä¿¡æ¯è·å–")
        return []
        
    # åˆ›å»ºæ‰¹æ¬¡
    batches = [ips[i:i + BATCH_SIZE] for i in range(0, len(ips), BATCH_SIZE)]
    results = []
    
    with tqdm(total=len(batches), desc="å¤„ç†IPæ‰¹æ¬¡") as pbar:
        with requests.Session() as session:
            with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
                futures = {executor.submit(ipinfoapi_batch, batch, session): batch for batch in batches}
                
                for future in concurrent.futures.as_completed(futures):
                    batch_result = future.result()
                    if batch_result:
                        results.extend(batch_result)
                    pbar.update(1)
    
    return results

def gather_ip_addresses(port):
    """æ”¶é›†æŒ‡å®šç«¯å£çš„IPåœ°å€"""
    port_dir = INPUT_DIR.format(port=port)
    
    if not os.path.exists(port_dir):
        logger.warning(f"ç«¯å£ {port} ç›®å½•ä¸å­˜åœ¨: {port_dir}")
        return []
    
    logger.info(f"æ‰«æç«¯å£ {port} ç›®å½•: {port_dir}")
    all_ips = []
    
    for file in os.listdir(port_dir):
        if file.endswith('.txt'):
            file_path = os.path.join(port_dir, file)
            all_ips.extend(get_ip_from_file(file_path))
    
    unique_ips = list(set(all_ips))
    logger.info(f"æ”¶é›†åˆ° {len(all_ips)} ä¸ªIPåœ°å€ï¼Œå»é‡å: {len(unique_ips)}")
    return unique_ips

def check_ip_port(ip, port, timeout=CHECK_TIMEOUT):
    """æ£€æµ‹IPç«¯å£æ˜¯å¦å¼€æ”¾"""
    try:
        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
            s.settimeout(timeout)
            result = s.connect_ex((ip, port))
            return result == 0
    except Exception:
        return False

def check_ip_ping(ip, timeout=CHECK_TIMEOUT):
    """æ£€æµ‹IPæ˜¯å¦å¯pingé€š"""
    param = '-n' if platform.system().lower() == 'windows' else '-c'
    command = ['ping', param, '1', '-w', str(int(timeout * 1000)), ip]
    
    try:
        # ä½¿ç”¨subprocess.PIPEé‡å®šå‘è¾“å‡ºï¼Œé¿å…æ§åˆ¶å°è¾“å‡º
        with subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE) as process:
            _, _ = process.communicate()
            return process.returncode == 0
    except Exception:
        return False

def check_ip(ip):
    """æ ¹æ®é…ç½®æ£€æµ‹IP"""
    if CHECK_METHOD == 'port':
        return check_ip_port(ip, CHECK_PORT, CHECK_TIMEOUT)
    elif CHECK_METHOD == 'ping':
        return check_ip_ping(ip, CHECK_TIMEOUT)
    else:
        logger.warning(f"æœªçŸ¥çš„æ£€æµ‹æ–¹æ³•: {CHECK_METHOD}, é»˜è®¤ä½¿ç”¨ç«¯å£æ£€æµ‹")
        return check_ip_port(ip, CHECK_PORT, CHECK_TIMEOUT)

def check_ips(ips):
    """æ‰¹é‡æ£€æµ‹IPå¯ç”¨æ€§"""
    if not ENABLE_IP_CHECK:
        logger.info("IPæ£€æµ‹å·²ç¦ç”¨ï¼Œè·³è¿‡æ£€æµ‹")
        return [True] * len(ips)
    
    logger.info(f"å¼€å§‹æ£€æµ‹ {len(ips)} ä¸ªIPçš„å¯ç”¨æ€§ (æ–¹æ³•: {CHECK_METHOD})")
    
    valid_ips = []
    lock = threading.Lock()
    
    def check_and_record(ip):
        result = check_ip(ip)
        with lock:
            valid_ips.append((ip, result))
    
    with tqdm(total=len(ips), desc="æ£€æµ‹IPå¯ç”¨æ€§") as pbar:
        with concurrent.futures.ThreadPoolExecutor(max_workers=CHECK_THREADS) as executor:
            futures = {executor.submit(check_and_record, ip): ip for ip in ips}
            
            for future in concurrent.futures.as_completed(futures):
                pbar.update(1)
    
    # æŒ‰åŸå§‹é¡ºåºè¿”å›ç»“æœ
    result_map = {ip: result for ip, result in valid_ips}
    return [result_map.get(ip, False) for ip in ips]

def process_ip_info(ip_info, port):
    """å¤„ç†IPä¿¡æ¯å¹¶æŒ‰å›½å®¶ä¿å­˜"""
    if not ip_info:
        logger.warning(f"æ²¡æœ‰è·å–åˆ°IPä¿¡æ¯ï¼Œè·³è¿‡å¤„ç†ç«¯å£ {port}")
        return
        
    save_dir = OUTPUT_DIR.format(port=port)
    os.makedirs(save_dir, exist_ok=True)

    try:
        df = pd.DataFrame(ip_info)
        
        # æ£€æµ‹IPå¯ç”¨æ€§
        ips = df['query'].tolist()
        valid_results = check_ips(ips)
        df['valid'] = valid_results
        
        # åªä¿ç•™æœ‰æ•ˆçš„IP
        valid_df = df[df['valid']]
        logger.info(f"æœ‰æ•ˆIPæ•°é‡: {len(valid_df)}/{len(df)}")
        
        grouped = valid_df.groupby('countryCode')
        
        for country_code, group in grouped:
            unique_ips = group['query'].drop_duplicates()
            output_file = os.path.join(save_dir, f"{country_code}.txt")
            unique_ips.to_csv(output_file, header=None, index=False)
            logger.info(f"ä¿å­˜ {country_code} çš„ {len(unique_ips)} ä¸ªæœ‰æ•ˆIPåˆ° {output_file}")
            
            # ä¿å­˜åŒ…å«æ‰€æœ‰ä¿¡æ¯çš„CSVæ–‡ä»¶
            info_file = os.path.join(save_dir, f"{country_code}_info.csv")
            group.to_csv(info_file, index=False)
            logger.info(f"ä¿å­˜ {country_code} çš„è¯¦ç»†ä¿¡æ¯åˆ° {info_file}")
    except Exception as e:
        logger.error(f"å¤„ç†IPä¿¡æ¯æ—¶å‡ºé”™: {e}")
        if ip_info:
            logger.debug(f"æ•°æ®ç»“æ„ç¤ºä¾‹: {ip_info[:1]}")

def create_country_marker_files(port):
    """ä¸ºæŒ‡å®šå›½å®¶åˆ›å»ºå¸¦æ ‡è®°çš„æ–‡ä»¶ï¼ˆåªå¤åˆ¶å‰10ä¸ªè®°å½•ï¼‰"""
    base_dir = OUTPUT_DIR.format(port=port)
    
    for country in COUNTRIES:
        source_path = os.path.join(base_dir, f"{country}.txt")
        target_path = os.path.join(base_dir, f"{country}_marked.txt")
        
        if not os.path.exists(source_path):
            logger.warning(f"å›½å®¶æ–‡ä»¶ä¸å­˜åœ¨: {source_path}")
            continue
            
        try:
            # è¯»å–æºæ–‡ä»¶ï¼Œåªå–å‰MAX_RECORDSè¡Œ
            with open(source_path, "r", encoding="utf-8") as src:
                lines = [line.strip() for line in src.readlines()[:MAX_RECORDS]]
            
            # å†™å…¥ç›®æ ‡æ–‡ä»¶ï¼Œæ·»åŠ æ ‡è®°
            with open(target_path, "w", encoding="utf-8") as tgt:
                for line in lines:
                    if line:  # è·³è¿‡ç©ºè¡Œ
                        tgt.write(f"{line}#{country}ğŸ¬\n")
            
            logger.info(f"å·²åˆ›å»ºæ ‡è®°æ–‡ä»¶: {target_path} (åŒ…å« {len(lines)} æ¡è®°å½•)")
        except Exception as e:
            logger.error(f"å¤„ç† {country} æ–‡ä»¶æ—¶å‡ºé”™: {e}")

def main(ports):
    """ä¸»å¤„ç†å‡½æ•°"""
    if isinstance(ports, str):
        ports = [p.strip() for p in ports.split(',')]
    
    for port in ports:
        logger.info(f"å¼€å§‹å¤„ç†ç«¯å£ {port}")
        ips = gather_ip_addresses(port)
        
        if not ips:
            logger.warning("æ²¡æœ‰æ‰¾åˆ°IPåœ°å€ï¼Œè·³è¿‡APIè°ƒç”¨")
            # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
            os.makedirs(OUTPUT_DIR.format(port=port), exist_ok=True)
            continue
            
        ip_info = get_ip_info(ips)
        process_ip_info(ip_info, port)
        create_country_marker_files(port)
        logger.info(f"ç«¯å£ {port} å¤„ç†å®Œæˆ")

if __name__ == "__main__":
    # ä»é…ç½®è·å–è¦å¤„ç†çš„ç«¯å£
    ports_config = get_config_value('settings', 'ports', '443')
    
    logger.info("=" * 50)
    logger.info(f"IPä¿¡æ¯æ”¶é›†å™¨å¯åŠ¨")
    logger.info(f"é…ç½®å‚æ•°:")
    logger.info(f"  è¾“å…¥ç›®å½•: {INPUT_DIR}")
    logger.info(f"  è¾“å‡ºç›®å½•: {OUTPUT_DIR}")
    logger.info(f"  æ‰¹å¤„ç†å¤§å°: {BATCH_SIZE}")
    logger.info(f"  æœ€å¤§é‡è¯•æ¬¡æ•°: {MAX_RETRIES}")
    logger.info(f"  å·¥ä½œçº¿ç¨‹æ•°: {MAX_WORKERS}")
    logger.info(f"  å¤„ç†å›½å®¶: {', '.join(COUNTRIES)}")
    logger.info(f"  æ¯ä¸ªå›½å®¶æœ€å¤§è®°å½•æ•°: {MAX_RECORDS}")
    logger.info(f"  å¤„ç†ç«¯å£: {ports_config}")
    logger.info(f"  IPæ£€æµ‹å¯ç”¨: {ENABLE_IP_CHECK}")
    if ENABLE_IP_CHECK:
        logger.info(f"  æ£€æµ‹æ–¹æ³•: {CHECK_METHOD}")
        if CHECK_METHOD == 'port':
            logger.info(f"  æ£€æµ‹ç«¯å£: {CHECK_PORT}")
        logger.info(f"  æ£€æµ‹è¶…æ—¶: {CHECK_TIMEOUT}ç§’")
        logger.info(f"  æ£€æµ‹çº¿ç¨‹æ•°: {CHECK_THREADS}")
    logger.info("=" * 50)
    
    try:
        main(ports_config)
        logger.info("æ‰€æœ‰å¤„ç†å®Œæˆ!")
    except Exception as e:
        logger.exception("å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿä¸¥é‡é”™è¯¯")
